{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "# Step 2: Load and Inspect the Data\n",
    "file_path = 'Bangalore_1990_2022_BangaloreCity.csv'  # Update this path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "print(\"Data Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# We will use the 'tavg' column for average temperature prediction\n",
    "df = df.dropna(subset=['tavg'])  # Remove rows where 'tavg' is NaN\n",
    "df['time'] = pd.to_datetime(df['time'], format='%d-%m-%Y')\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "# Visualize the temperature data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['tavg'], label='Average Temperature over time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Average Temperature Trend in Bangalore')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Prepare the Data for GRU\n",
    "# Normalize the temperature data for better performance\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['tavg'] = scaler.fit_transform(df[['tavg']])\n",
    "\n",
    "# Convert data into a supervised learning problem\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:(i + look_back), 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "look_back = 30  # Number of previous time steps to consider\n",
    "data = df['tavg'].values.reshape(-1, 1)\n",
    "X, y = create_dataset(data, look_back)\n",
    "\n",
    "# Reshape the input to be [samples, time steps, features] for GRU input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Step 5: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Build the GRU Model with Updated Hyperparameters\n",
    "model = Sequential()\n",
    "\n",
    "# First GRU layer with 240 units and ReLU activation\n",
    "model.add(GRU(240, activation='relu', input_shape=(look_back, 1), return_sequences=True))\n",
    "\n",
    "# Second GRU layer with 240 units and ELU activation\n",
    "model.add(GRU(240, activation='elu'))\n",
    "\n",
    "# Dense output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model with updated learning rate and loss function\n",
    "model.compile(optimizer=Adam(learning_rate=0.00015), loss='mean_squared_error')\n",
    "\n",
    "# Step 7: Train the Model\n",
    "epochs = 20  # Updated to match the specified hyperparameters\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Make Predictions and Inverse Transform to Actual Scale\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Step 10: Calculate Accuracy and Plot Results\n",
    "train_score = math.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "test_score = math.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "print(f\"Train RMSE: {train_score:.2f}\")\n",
    "print(f\"Test RMSE: {test_score:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_inv, label='Actual Temperature')\n",
    "plt.plot(test_predict, label='Predicted Temperature')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Temperature Prediction vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display Mean Absolute Error (MAE)\n",
    "train_mae = mean_absolute_error(y_train_inv, train_predict)\n",
    "test_mae = mean_absolute_error(y_test_inv, test_predict)\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "\n",
    "# Step 11: Calculate R-squared and Accuracy Percentage\n",
    "train_r2 = r2_score(y_train_inv, train_predict)\n",
    "test_r2 = r2_score(y_test_inv, test_predict)\n",
    "train_accuracy = train_r2 * 100\n",
    "test_accuracy = test_r2 * 100\n",
    "print(f\"Train R² Score: {train_r2:.2f}\")\n",
    "print(f\"Test R² Score: {test_r2:.2f}\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Step 12: Conclusion and Analysis\n",
    "print(\"The GRU model provides a reasonable prediction of future temperatures.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
